{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import torch.multiprocessing\r\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\r\n",
    "import torch  \r\n",
    "import torchvision\r\n",
    "from PIL import Image\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import torchvision.transforms as transforms \r\n",
    "import numpy as np\r\n",
    "from sklearn import *\r\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pls refer to https://pytorch.org/docs/stable/data.html\r\n",
    "class EE4146_Dataset(torch.utils.data.Dataset):\r\n",
    "    def __init__(self, csv_path, file_path):\r\n",
    "        \"\"\"\r\n",
    "        Args:\r\n",
    "            csv_path (string): csv \r\n",
    "            img_path (string): \r\n",
    "            transform: transform \r\n",
    "        \"\"\"\r\n",
    "        self.file_path = file_path\r\n",
    "        self.to_tensor = transforms.ToTensor() \r\n",
    "        self.data_info = pd.read_csv(csv_path, header=0) \r\n",
    "        self.image_arr = np.asarray(data_info.iloc[:, 0])\r\n",
    "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\r\n",
    "        self.data_len = len(self.data_info.index)\r\n",
    "        self.encode_labels = dict( zip(np.unique(self.label_arr), range(len(np.unique(self.label_arr)))))\r\n",
    "        print('encoded labels: ', self.encode_labels)\r\n",
    "        self.transform = torchvision.transforms.Compose([\r\n",
    "                    transforms.Resize((150,150)),\r\n",
    "                    transforms.ToTensor(),\r\n",
    "                    transforms.Normalize((0.425, 0.415, 0.405), (0.255, 0.245, 0.235))\r\n",
    "                    ])\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        img_id = self.image_arr[index]\r\n",
    "        img_as_img = Image.open(self.file_path + str(img_id) + \".jpg\")\r\n",
    "        img_as_img = self.transform(img_as_img)\r\n",
    "        label = self.encode_labels[self.label_arr[index]]\r\n",
    "        return (img_as_img, label, img_id)  \r\n",
    "        \r\n",
    "    def __len__(self):\r\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pretrained deep feature extractor\r\n",
    "model = torchvision.models.wide_resnet50_2(pretrained=True).cuda()\r\n",
    "for param in model.parameters():\r\n",
    "    param.required_grad = False\r\n",
    "\r\n",
    "# Replacing the final classifier by identity layer (for directly out features)\r\n",
    "model.fc = torch.nn.Identity()\r\n",
    "model.eval()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded labels:  {'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n"
     ]
    }
   ],
   "source": [
    "# Define dataloaded\r\n",
    "train_data = EE4146_Dataset('train_labels.csv','raw_images/train/' )\r\n",
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=8,num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference and save features\r\n",
    "label_save = []\r\n",
    "feats_save = []\r\n",
    "feat_save_path = 'train_feat/'\r\n",
    "\r\n",
    "if not os.path.exists(feat_save_path):\r\n",
    "    os.makedirs(feat_save_path)\r\n",
    "\r\n",
    "for images, labels, image_ids in train_loader:\r\n",
    "    B, C, W, H = images.shape\r\n",
    "    feat = model(images.cuda()).detach().cpu()\r\n",
    "    feats_save.append(feat) # B 2024\r\n",
    "    label_save.append(labels)\r\n",
    "    for i, imgID in enumerate(image_ids):\r\n",
    "        np.save(feat_save_path +'{}_feat_res50.npy'.format(imgID), feat[i].numpy())\r\n",
    "\r\n",
    "feats_save = torch.cat(feats_save,dim=0)\r\n",
    "label_save = torch.cat(label_save)\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0291dae3f3753d9be93daa3086b416758fd0bf0e721c90dd4b06147e6372b63"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "name": "python368jvsc74a57bd0a2136d017e034ab9e07bf99caaf038b2779747873029d460ec8b1336a7375585"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}